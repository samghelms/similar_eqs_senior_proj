{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "\n",
    "def compute_log_lik(T, e_list, f_list):\n",
    "    cur_log_lik = 0\n",
    "    log_sum = None\n",
    "    e = None\n",
    "    f = None\n",
    "    n = len(e_list)\n",
    "    # e list = f _list len\n",
    "    for i in range(n):\n",
    "        e = e_list[i]\n",
    "        f = f_list[i]\n",
    "        for e_t in e:\n",
    "            log_sum = 0\n",
    "            for f_t in f:\n",
    "                log_sum += T[e_t, f_t]\n",
    "            cur_log_lik += np.log(log_sum)\n",
    "    return cur_log_lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def _inner_log_lik(e, f, T):\n",
    "    cur_log_lik = 0\n",
    "    for e_t in e:\n",
    "        log_sum = 0\n",
    "        for f_t in f:\n",
    "            log_sum += T[e_t, f_t]\n",
    "        cur_log_lik += np.log(log_sum)\n",
    "    return cur_log_lik\n",
    "\n",
    "\n",
    "def compute_log_lik(T, pairs):\n",
    "    cur_log_lik = 0\n",
    "    # e list = f _list len\n",
    "    for e, f in pairs:\n",
    "        cur_log_lik += _inner_log_lik(e, f, T)\n",
    "    return cur_log_lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 ms ± 2.92 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit compute_log_lik(np.ones((100,100), dtype=np.float32), [[j for j in range(i)] for i in range(1, 100)], [[j for j in range(i)] for i in range(1, 100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.67 ms ± 108 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit compute_log_lik_numba(np.ones((100,100), dtype=np.float32), [[j for j in range(i)] for i in range(1, 100)], [[j for j in range(i)] for i in range(1, 100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def _estimate(T, pairs, start_log_lik, tol):\n",
    "    prev_log_lik = -np.inf\n",
    "    counts = np.zeros(T.shape)\n",
    "    total = np.zeros(T.shape[1])\n",
    "    it_counter = 0\n",
    "    cur_log_lik = start_log_lik\n",
    "    while (cur_log_lik - prev_log_lik) > tol:\n",
    "        start_it_time = time.clock()\n",
    "#         print(\"current log likelihood: {cur_log_lik}\".format(cur_log_lik=cur_log_lik))\n",
    "        for e, f in pairs:\n",
    "            # compute normalization\n",
    "            s_total = np.zeros(T.shape[0])\n",
    "            for e_t in e:\n",
    "                for f_t in f:\n",
    "                    s_total[e_t] += T[e_t, f_t]\n",
    "\n",
    "            # counts\n",
    "            for e_t in e:\n",
    "                for f_t in f:\n",
    "                    counts[e_t, f_t] += T[e_t, f_t] / s_total[e_t]\n",
    "                    total[f_t] += T[e_t, f_t] / s_total[e_t]\n",
    "\n",
    "        for e_t in range(T.shape[0]):\n",
    "            for f_t in range(T.shape[1]):\n",
    "                T[e_t, f_t] = counts[e_t, f_t] / total[f_t]\n",
    "\n",
    "        prev_log_lik = cur_log_lik\n",
    "        cur_log_lik = compute_log_lik(T, pairs)\n",
    "\n",
    "#         print(\"time taken for loop {it}: {time}\".format(it=str(it_counter),\n",
    "#             time=str(time.clock() - start_it_time)))\n",
    "        # serialize\n",
    "#         pickle.dump(T, open('T_'+str(it_counter)+'.pkl', 'wb+'))\n",
    "        it_counter += 1\n",
    "    return T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# @jit(nopython=True)\n",
    "def _estimate_numba_inner(e, f, s_total, counts, total):\n",
    "    for e_t in e:\n",
    "        for f_t in f:\n",
    "            s_total[e_t] += T[e_t, f_t]\n",
    "\n",
    "    # counts\n",
    "    for e_t in e:\n",
    "        for f_t in f:\n",
    "            counts[e_t, f_t] += T[e_t, f_t] / s_total[e_t]\n",
    "            total[f_t] += T[e_t, f_t] / s_total[e_t]\n",
    "\n",
    "@jit(nopython=True)\n",
    "def _fill_T(T, counts, total):\n",
    "    for e_t in range(T.shape[0]):\n",
    "        for f_t in range(T.shape[1]):\n",
    "            T[e_t, f_t] = counts[e_t, f_t] / (total[f_t] + 0.00001)\n",
    "\n",
    "\n",
    "def _estimate_numba(T, pairs, start_log_lik, tol):\n",
    "    prev_log_lik = -np.inf\n",
    "    counts = np.zeros(T.shape)\n",
    "    total = np.zeros(T.shape[1])\n",
    "    it_counter = 0\n",
    "    cur_log_lik = start_log_lik\n",
    "    while (cur_log_lik - prev_log_lik) > tol:\n",
    "        start_it_time = time.clock()\n",
    "#         print(\"current log likelihood: {cur_log_lik}\".format(cur_log_lik=cur_log_lik))\n",
    "        for e, f in pairs:\n",
    "            # compute normalization\n",
    "            s_total = np.zeros(T.shape[0])\n",
    "            _estimate_numba_inner(e, f, s_total, counts, total)\n",
    "\n",
    "        _fill_T(T, counts, total)\n",
    "\n",
    "        prev_log_lik = cur_log_lik\n",
    "        cur_log_lik = compute_log_lik(T, pairs)\n",
    "\n",
    "#         print(\"time taken for loop {it}: {time}\".format(it=str(it_counter),\n",
    "#             time=str(time.clock() - start_it_time)))\n",
    "        # serialize\n",
    "#         pickle.dump(T, open('T_'+str(it_counter)+'.pkl', 'wb+'))\n",
    "        it_counter += 1\n",
    "    return T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "T = np.ones((n,n), dtype=np.float32) * 1 / n\n",
    "\n",
    "e = [[j-1 for j in range(n)] for i in range(1, n)]\n",
    "f = [[j-1 for j in range(n)] for i in range(1, n)]\n",
    "pairs = zip(e, f)\n",
    "start_log_lik = compute_log_lik(T, pairs)\n",
    "tol = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/miniconda3/envs/data_cleaning/lib/python3.6/site-packages/ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.1 ms ± 1.14 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _estimate(T, pairs, start_log_lik, tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.3 µs ± 11 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _estimate_numba(T, pairs, start_log_lik, tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_cleaning",
   "language": "python",
   "name": "data_cleaning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
