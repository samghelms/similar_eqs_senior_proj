
@inproceedings{schnabel_evaluation_2015,
	title = {Evaluation methods for unsupervised word embeddings},
	doi = {10.18653/v1/D15-1036},
	author = {Schnabel, Tobias and Labutov, Igor and Mimno, David and Joachims, Thorsten},
	month = jan,
	year = {2015},
	pages = {298--307}
}

@misc{samghelms_embeddings-viz:_2018,
	title = {embeddings-viz: demo of visualization tool {I}'ve been building using three.js and react},
	shorttitle = {embeddings-viz},
	howpublished = {https://github.com/samghelms/embeddings-viz},
	urldate = {2018-02-02},
	author = {Samuel Helms},
	month = jan,
	year = {2018},
	note = {original-date: 2018-01-19T22:18:35Z},
	file = {Snapshot:/Users/sam/Zotero/storage/JIIGW36U/embeddings-viz.html:text/html}
}

@misc{noauthor_react_nodate,
	title = {React {App}},
	howpublished = {http://ood.cs.uchicago.edu:5000/},
	urldate = {2018-02-02},
	author = {Samuel Helms},
	file = {React App:/Users/sam/Zotero/storage/DIKV4ZEN/ood.cs.uchicago.edu.html:text/html}
}

@misc{samghelms_mathviz:_2017,
	title = {mathviz: {A} python package for examining mathematics equation embeddings},
	copyright = {MIT},
	shorttitle = {mathviz},
	howpublished = {https://github.com/samghelms/mathviz},
	urldate = {2018-02-02},
	author = {Samuel Helms},
	month = dec,
	year = {2017},
	note = {original-date: 2017-11-01T23:40:18Z},
	file = {Snapshot:/Users/sam/Zotero/storage/H7V8QRUA/mathviz.html:text/html}
}

@article{mikolov_distributed_2013,
	title = {Distributed {Representations} of {Words} and {Phrases} and their {Compositionality}},
	url = {http://arxiv.org/abs/1310.4546},
	abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of "Canada" and "Air" cannot be easily combined to obtain "Air Canada". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.},
	urldate = {2018-02-02},
	journal = {arXiv:1310.4546 [cs, stat]},
	author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	month = oct,
	year = {2013},
	note = {arXiv: 1310.4546},
	keywords = {Computer Science - Computation and Language, Statistics - Machine Learning, Computer Science - Learning},
	file = {arXiv\:1310.4546 PDF:/Users/sam/Zotero/storage/5KQL66IR/Mikolov et al. - 2013 - Distributed Representations of Words and Phrases a.pdf:application/pdf;arXiv.org Snapshot:/Users/sam/Zotero/storage/XSGEN36P/1310.html:text/html}
}

@inproceedings{pennington_glove:_2014,
	title = {Glove: {Global} {Vectors} for {Word} {Representation}},
	booktitle = {{EMNLP}},
	author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher D.},
	year = {2014}
}

@inproceedings{ramos_using_2003,
	title = {Using {TF}-{IDF} to {Determine} {Word} {Relevance} in {Document} {Queries}},
	author = {Ramos, Juan David Hincapi√©},
	year = {2003}
}

@misc{noauthor_neural_nodate,
	title = {A {Neural} {Network} for {Machine} {Translation}, at {Production} {Scale}},
	url = {https://research.googleblog.com/2016/09/a-neural-network-for-machine.html},
	abstract = {Posted by Quoc V. Le \& Mike Schuster, Research Scientists, Google Brain Team   Ten years ago, we announced the launch of Google Translate , ...},
	language = {en},
	urldate = {2018-02-02},
	journal = {Research Blog},
	file = {Snapshot:/Users/sam/Zotero/storage/V42C9XR2/a-neural-network-for-machine.html:text/html}
}